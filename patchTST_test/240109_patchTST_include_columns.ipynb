{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/estsoft/miniconda3/envs/leejo/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.auto import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../../../estsoft/data/train.csv\")\n",
    "def fill_null(df:pd.DataFrame, time_before:list, time:list, time_after:list):\n",
    "    df_fill = pd.DataFrame()\n",
    "    for i in range(len(time_before)):\n",
    "        df_null = df[df['datetime']==time[i]]\n",
    "        df_concat = pd.concat([df[df['datetime']==time_before[i]], df[df['datetime']==time_after[i]]])\n",
    "\n",
    "        # null값의 앞뒤 시간의 평균값 계산 및 저장\n",
    "        ab_mean = pd.DataFrame(df_concat.groupby(['prediction_unit_id'])['target'].sum()/2).reset_index()\n",
    "        df_merge = pd.merge(df_null, ab_mean, how='left', on='prediction_unit_id').drop(columns='target_x').rename(columns={'target_y':'target'})\n",
    "        df_fill = pd.concat([df_fill, df_merge])\n",
    "\n",
    "        # null값이 있는 행 drop\n",
    "        df = df.drop(df_null.index)\n",
    "\n",
    "    df = pd.concat([df, df_fill]).reset_index(drop=True).sort_values(by='datetime')\n",
    "    return df\n",
    "df_prod =df[df['is_consumption']==0]\n",
    "df_cons = df[df['is_consumption']==1]\n",
    "\n",
    "time_before = ['2022-10-30 02:00:00', '2022-03-27 02:00:00', '2023-03-26 02:00:00', '2021-10-31 02:00:00']\n",
    "time = ['2022-10-30 03:00:00', '2022-03-27 03:00:00', '2023-03-26 03:00:00', '2021-10-31 03:00:00']\n",
    "time_after = ['2022-10-30 04:00:00', '2022-03-27 04:00:00', '2023-03-26 04:00:00', '2021-10-31 04:00:00']\n",
    "\n",
    "df_prod = fill_null(df_prod, time_before, time, time_after)\n",
    "df_cons = fill_null(df_cons, time_before, time, time_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1009176 entries, 0 to 1008853\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count    Dtype         \n",
      "---  ------              --------------    -----         \n",
      " 0   county              1009176 non-null  int64         \n",
      " 1   is_business         1009176 non-null  int64         \n",
      " 2   product_type        1009176 non-null  int64         \n",
      " 3   target              1009176 non-null  float64       \n",
      " 4   is_consumption      1009176 non-null  int64         \n",
      " 5   datetime            1009176 non-null  datetime64[ns]\n",
      " 6   data_block_id       1009176 non-null  int64         \n",
      " 7   row_id              1009176 non-null  int64         \n",
      " 8   prediction_unit_id  1009176 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(7)\n",
      "memory usage: 77.0 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1009176 entries, 0 to 1008853\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count    Dtype         \n",
      "---  ------              --------------    -----         \n",
      " 0   county              1009176 non-null  int64         \n",
      " 1   is_business         1009176 non-null  int64         \n",
      " 2   product_type        1009176 non-null  int64         \n",
      " 3   target              1009176 non-null  float64       \n",
      " 4   is_consumption      1009176 non-null  int64         \n",
      " 5   datetime            1009176 non-null  datetime64[ns]\n",
      " 6   data_block_id       1009176 non-null  int64         \n",
      " 7   row_id              1009176 non-null  int64         \n",
      " 8   prediction_unit_id  1009176 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(7)\n",
      "memory usage: 77.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_prod['datetime'] = pd.to_datetime(df_prod['datetime'])\n",
    "print(df_prod.info())\n",
    "df_prod.set_index('datetime', drop=True, inplace=True) \n",
    "\n",
    "df_cons['datetime'] = pd.to_datetime(df_cons['datetime'])\n",
    "print(df_cons.info())\n",
    "df_cons.set_index('datetime', drop=True, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f\"df_prod{n}\"\n",
    "df_prod_list = []\n",
    "for id in df_prod['prediction_unit_id'].unique():\n",
    "    exec(f\"df_prod{id} = df_prod[df_prod['prediction_unit_id']=={id}]\")\n",
    "    exec(f\"df_prod_list.append('df_prod{id}')\")\n",
    "\n",
    "# f\"df_cons{n}\"\n",
    "df_cons_list = []\n",
    "for id in df_cons['prediction_unit_id'].unique():\n",
    "    exec(f\"df_cons{id} = df_cons[df_cons['prediction_unit_id']=={id}]\")\n",
    "    exec(f\"df_cons_list.append('df_cons{id}')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(df_prod0[['target', 'is_business']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PatchTST \n",
    "- include column \"is_business\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchTSDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, ts:np.array, patch_length:int=16, n_patches:int=6, prediction_length:int=4):\n",
    "    self.P = patch_length\n",
    "    self.N = n_patches\n",
    "    self.L = int(patch_length * n_patches / 2)  # look-back window length\n",
    "    self.T = prediction_length\n",
    "    self.data = ts\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data) - self.L - self.T + 1\n",
    "\n",
    "  def __getitem__(self, i):\n",
    "    look_back = self.data[i:(i+self.L)]\n",
    "    look_back = np.concatenate([look_back, look_back[-1]*np.ones(int(self.P / 2), dtype=np.float32)])\n",
    "    x = np.array([look_back[i*int(self.P/2):(i+2)*int(self.P/2)] for i in range(self.N)])\n",
    "    y = self.data[(i+self.L):(i+self.L+self.T)]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "patch_length = 16\n",
    "n_patches = 8\n",
    "prediction_length = 4\n",
    "window_size = int(patch_length * n_patches / 2)\n",
    "tst_size = 96\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "trn_scaled = scaler.fit_transform(data[:-tst_size].to_numpy(dtype=np.float32)).flatten()\n",
    "tst_scaled = scaler.transform(data[-tst_size-window_size:].to_numpy(dtype=np.float32)).flatten()\n",
    "\n",
    "trn_ds = PatchTSDataset(trn_scaled, patch_length, n_patches)\n",
    "tst_ds = PatchTSDataset(tst_scaled, patch_length, n_patches)\n",
    "\n",
    "trn_dl = torch.utils.data.DataLoader(trn_ds, batch_size=32, shuffle=True)\n",
    "tst_dl = torch.utils.data.DataLoader(tst_ds, batch_size=tst_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 8, 16]), torch.Size([32, 4]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(trn_dl))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_data = data.copy()\n",
    "m_data['rolling_mean'] = data.target.rolling(11).mean()\n",
    "m_data = m_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler2 = MinMaxScaler()\n",
    "\n",
    "trn2_scaled = scaler2.fit_transform(m_data['rolling_mean'][:-tst_size].to_numpy(dtype=np.float32).reshape(-1,1)).flatten()\n",
    "\n",
    "trn2_ds = PatchTSDataset(trn2_scaled, patch_length, n_patches)\n",
    "\n",
    "trn_ds = torch.utils.data.ConcatDataset([trn_ds, trn2_ds])\n",
    "\n",
    "trn_dl = torch.utils.data.DataLoader(trn_ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 8, 16]), torch.Size([32, 4]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(trn_dl))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchTST(nn.Module):\n",
    "  def __init__(self, n_token, input_dim, model_dim, num_heads, num_layers, output_dim):\n",
    "    super(PatchTST, self).__init__()\n",
    "    self.patch_embedding = nn.Linear(input_dim, model_dim)    # Input Embedding\n",
    "    self._pos = torch.nn.Parameter(torch.randn(1,1,model_dim))  # Positional Embedding\n",
    "\n",
    "    encoder_layers = nn.TransformerEncoderLayer(d_model=model_dim, nhead=num_heads, batch_first=True)\n",
    "    self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "\n",
    "    self.output_layer = nn.Linear(model_dim * n_token, output_dim)\n",
    "\n",
    "  def forward(self, x):\n",
    "    # x shape: (batch_size, n_token, token_size)\n",
    "    x = self.patch_embedding(x)   # (batch_size, n_token, model_dim)\n",
    "    x = x + self._pos\n",
    "    x = self.transformer_encoder(x)   # (batch_size, n_token, model_dim)\n",
    "    x = x.view(x.size(0), -1)       # (batch_size, n_token * model_dim)\n",
    "    output = self.output_layer(x)   # (batch_size, out_dim =4 patch_size == 4)\n",
    "    return F.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:17<00:00, 13.79s/it, loss=0.000617, tst_loss=0.00323]\n"
     ]
    }
   ],
   "source": [
    "model = PatchTST(n_patches, patch_length, 128, 8, 4, prediction_length)\n",
    "model.to(device)\n",
    "\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "\n",
    "pbar = trange(10)\n",
    "for _ in pbar:\n",
    "  model.train()\n",
    "  trn_loss = 0.\n",
    "  for x,y in trn_dl:\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    p = model(x)\n",
    "    optim.zero_grad()\n",
    "    loss = F.mse_loss(p, y)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    trn_loss += loss.item()*len(x)\n",
    "  trn_loss = trn_loss / len(trn_ds)\n",
    "\n",
    "  model.eval()\n",
    "  with torch.inference_mode():\n",
    "    x, y = next(iter(tst_dl))\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    p = model(x)\n",
    "    tst_loss = F.mse_loss(p,y)\n",
    "  pbar.set_postfix({'loss':trn_loss, 'tst_loss':tst_loss.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_pred, y_true):\n",
    "  return (np.abs(y_pred - y_true)/y_true).mean() * 100\n",
    "\n",
    "def mae(y_pred, y_true):\n",
    "  return np.abs(y_pred - y_true).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (96,4) (2,) (96,4) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m   x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m   p \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m---> 10\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m p \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(p\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[1;32m     13\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([y[:,\u001b[38;5;241m0\u001b[39m], y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m:]])\n",
      "File \u001b[0;32m/home/estsoft/miniconda3/envs/leejo/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:547\u001b[0m, in \u001b[0;36mMinMaxScaler.inverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    541\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    543\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m    544\u001b[0m     X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy, dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m )\n\u001b[0;32m--> 547\u001b[0m X \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_\n\u001b[1;32m    548\u001b[0m X \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (96,4) (2,) (96,4) "
     ]
    }
   ],
   "source": [
    "# model = PatchTST(n_patches, patch_length, 128, 8, 4, prediction_length), epoch 10\n",
    "res_dict = {}\n",
    "\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "  x, y = next(iter(tst_dl))\n",
    "  x, y = x.to(device), y.to(device)\n",
    "  p = model(x)\n",
    "\n",
    "y = scaler.inverse_transform(y.cpu())\n",
    "p = scaler.inverse_transform(p.cpu())\n",
    "\n",
    "y = np.concatenate([y[:,0], y[-1,1:]])\n",
    "p = np.concatenate([p[:,0], p[-1,1:]])\n",
    "\n",
    "plt.title(f\"PatchTST (extended dataset), MAPE:{mape(torch.Tensor(p),torch.Tensor(y)):.4f}, MAE:{mae(torch.Tensor(p),torch.Tensor(y)):.4f}\")\n",
    "plt.plot(range(tst_size), y, label=\"True\")\n",
    "plt.plot(range(tst_size), p, label=\"Prediction\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "res_dict.update({'PatchTST/8': {'MAPE':mape(p,y), 'MAE':mae(p,y)}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(res_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leejo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
